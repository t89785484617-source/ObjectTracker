#!/usr/bin/env python3
"""
Production RTSP to YOLO Processor - ADVANCED OBJECT TRACKING
"""

import cv2
import time
import logging
import subprocess
import numpy as np
import select
import threading
from flask import Flask, Response
from ultralytics import YOLO
import queue
import json
from datetime import datetime
import sys
from collections import OrderedDict, deque
import scipy.spatial as sp
from scipy.optimize import linear_sum_assignment

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('rtsp_yolo_processor.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class Config:
    def __init__(self):
        self.rtsp_url = "rtsp://admin:Jaquio@192.168.15.166:554/live"
        self.model_path = "yolov8n.pt"
        
        # –§–ò–ö–°–ò–†–û–í–ê–ù–ù–´–ï –†–ê–ó–ú–ï–†–´
        self.capture_width = 1920
        self.capture_height = 1080
        
        # –†–∞–∑–º–µ—Ä—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ YOLO
        self.processing_width = 640
        self.processing_height = 360
        
        # –†–∞–∑–º–µ—Ä—ã –¥–ª—è –≤–µ–±-–≤—ã–≤–æ–¥–∞
        self.web_width = 854
        self.web_height = 480
        
        self.target_fps = 20
        self.process_every_n = 3
        self.confidence_threshold = 0.5
        self.web_host = "0.0.0.0"
        self.web_port = 8001
        self.web_quality = 60
        
        # –£–õ–£–ß–®–ï–ù–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –¢–†–ï–ö–ï–†–ê
        self.tracker_max_age = 30  # —É–≤–µ–ª–∏—á–µ–Ω —Å—Ä–æ–∫ –∂–∏–∑–Ω–∏ –æ–±—ä–µ–∫—Ç–∞
        self.tracker_min_hits = 3  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ü–∏–π –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        self.tracker_iou_threshold = 0.4  # –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥
        self.tracker_appearance_weight = 0.7  # –≤–µ—Å –≤–Ω–µ—à–Ω–µ–≥–æ –≤–∏–¥–∞ vs –¥–≤–∏–∂–µ–Ω–∏—è
        self.tracker_velocity_weight = 0.3  # –≤–µ—Å —Å–∫–æ—Ä–æ—Å—Ç–∏

class KalmanFilter:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π Kalman —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —Ç—Ä–µ–∫–∏–Ω–≥–∞ –æ–±—ä–µ–∫—Ç–æ–≤"""
    
    def __init__(self):
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ: [x, y, w, h, dx, dy]
        self.state = np.zeros(6)
        # –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
        self.covariance = np.eye(6) * 10
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –ø–æ—Å—Ç–æ—è–Ω–Ω—É—é —Å–∫–æ—Ä–æ—Å—Ç—å)
        self.transition_matrix = np.array([
            [1, 0, 0, 0, 1, 0],
            [0, 1, 0, 0, 0, 1],
            [0, 0, 1, 0, 0, 0],
            [0, 0, 0, 1, 0, 0],
            [0, 0, 0, 0, 1, 0],
            [0, 0, 0, 0, 0, 1]
        ])
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è (–∏–∑–º–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–∑–∏—Ü–∏—é –∏ —Ä–∞–∑–º–µ—Ä)
        self.observation_matrix = np.array([
            [1, 0, 0, 0, 0, 0],
            [0, 1, 0, 0, 0, 0],
            [0, 0, 1, 0, 0, 0],
            [0, 0, 0, 1, 0, 0]
        ])
        
        # –®—É–º –ø—Ä–æ—Ü–µ—Å—Å–∞
        self.process_noise = np.eye(6) * 0.03
        # –®—É–º –∏–∑–º–µ—Ä–µ–Ω–∏–π
        self.measurement_noise = np.eye(4) * 0.1
    
    def init(self, bbox):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∏–ª—å—Ç—Ä–∞ —Å bounding box"""
        x1, y1, x2, y2 = bbox
        w, h = x2 - x1, y2 - y1
        cx, cy = x1 + w/2, y1 + h/2
        self.state = np.array([cx, cy, w, h, 0, 0])
        self.covariance = np.eye(6) * 10
    
    def predict(self):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        self.state = self.transition_matrix @ self.state
        self.covariance = (self.transition_matrix @ self.covariance @ 
                          self.transition_matrix.T) + self.process_noise
        return self.get_bbox()
    
    def update(self, bbox):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è"""
        if bbox is None:
            return
        
        x1, y1, x2, y2 = bbox
        w, h = x2 - x1, y2 - y1
        cx, cy = x1 + w/2, y1 + h/2
        measurement = np.array([cx, cy, w, h])
        
        # Innovation
        y = measurement - self.observation_matrix @ self.state
        S = self.observation_matrix @ self.covariance @ self.observation_matrix.T + self.measurement_noise
        K = self.covariance @ self.observation_matrix.T @ np.linalg.inv(S)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.state = self.state + K @ y
        self.covariance = (np.eye(6) - K @ self.observation_matrix) @ self.covariance
    
    def get_bbox(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ bounding box –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        cx, cy, w, h, _, _ = self.state
        x1 = cx - w/2
        y1 = cy - h/2
        x2 = cx + w/2
        y2 = cy + h/2
        return [x1, y1, x2, y2]

class TrackedObject:
    """–¢—Ä–µ–∫–∞–µ–º—ã–π –æ–±—ä–µ–∫—Ç —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å—é ID"""
    
    def __init__(self, object_id, detection, config):
        self.object_id = object_id
        self.detection = detection
        self.class_name = detection['class_name']
        self.confidence = detection['confidence']
        
        # Kalman —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        self.kalman = KalmanFilter()
        self.kalman.init(detection['bbox'])
        
        # –ò—Å—Ç–æ—Ä–∏—è –ø–æ–∑–∏—Ü–∏–π –¥–ª—è —Ç—Ä–µ–∫–∏–Ω–≥–∞
        self.track_history = deque(maxlen=50)
        self.update_track_history()
        
        # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ç—Ä–µ–∫–∞
        self.hit_streak = 1  # –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
        self.age = 1  # –≤–æ–∑—Ä–∞—Å—Ç —Ç—Ä–µ–∫–∞ –≤ –∫–∞–¥—Ä–∞—Ö
        self.time_since_update = 0  # –≤—Ä–µ–º—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        
        # –í–∏–∑—É–∞–ª—å–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
        self.appearance_features = self._extract_appearance(detection['bbox'])
        
        self.config = config
    
    def _extract_appearance(self, bbox):
        """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π"""
        x1, y1, x2, y2 = bbox
        w, h = x2 - x1, y2 - y1
        aspect_ratio = w / h if h > 0 else 1.0
        area = w * h
        return np.array([w, h, aspect_ratio, area])
    
    def update_track_history(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–∑–∏—Ü–∏–π"""
        bbox = self.kalman.get_bbox()
        cx = (bbox[0] + bbox[2]) / 2
        cy = (bbox[1] + bbox[3]) / 2
        self.track_history.append((cx, cy))
    
    def predict(self):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–∑–∏—Ü–∏–∏"""
        predicted_bbox = self.kalman.predict()
        self.time_since_update += 1
        self.update_track_history()
        return predicted_bbox
    
    def update(self, detection):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –Ω–æ–≤–æ–π –¥–µ—Ç–µ–∫—Ü–∏–µ–π"""
        self.detection = detection
        self.confidence = detection['confidence']
        self.kalman.update(detection['bbox'])
        self.hit_streak += 1
        self.time_since_update = 0
        self.age += 1
        self.update_track_history()
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π
        self.appearance_features = self._extract_appearance(detection['bbox'])
    
    def similarity_score(self, detection):
        """–û—Ü–µ–Ω–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –Ω–æ–≤–æ–π –¥–µ—Ç–µ–∫—Ü–∏–µ–π"""
        bbox1 = self.kalman.get_bbox()
        bbox2 = detection['bbox']
        
        # 1. IoU (Intersection over Union)
        iou = self._calculate_iou(bbox1, bbox2)
        
        # 2. –°—Ö–æ–∂–µ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤
        class_similarity = 1.0 if self.class_name == detection['class_name'] else 0.0
        
        # 3. –°—Ö–æ–∂–µ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–∞ –∏ —Ñ–æ—Ä–º—ã
        features1 = self.appearance_features
        features2 = self._extract_appearance(bbox2)
        size_similarity = 1.0 - min(1.0, np.linalg.norm(features1 - features2) / 100)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        motion_similarity = iou * self.config.tracker_velocity_weight
        appearance_similarity = (class_similarity + size_similarity) / 2 * self.config.tracker_appearance_weight
        
        return motion_similarity + appearance_similarity
    
    def _calculate_iou(self, box1, box2):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ Intersection over Union"""
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        
        xi1 = max(x1_1, x1_2)
        yi1 = max(y1_1, y1_2)
        xi2 = min(x2_1, x2_2)
        yi2 = min(y2_1, y2_2)
        
        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
        box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)
        box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)
        union_area = box1_area + box2_area - inter_area
        
        return inter_area / union_area if union_area > 0 else 0

class AdvancedObjectTracker:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç—Ä–µ–∫–µ—Ä –æ–±—ä–µ–∫—Ç–æ–≤ —Å —Å—Ç–∞–±–∏–ª—å–Ω—ã–º–∏ ID"""
    
    def __init__(self, config):
        self.config = config
        self.next_object_id = 1
        self.tracked_objects = OrderedDict()  # object_id -> TrackedObject
        self.frames_since_update = 0
    
    def update(self, detections):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–µ—Ä–∞ —Å –Ω–æ–≤—ã–º–∏ –¥–µ—Ç–µ–∫—Ü–∏—è–º–∏"""
        self.frames_since_update += 1
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –≤—Å–µ—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        for obj in self.tracked_objects.values():
            obj.predict()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã —Å—Ö–æ–∂–µ—Å—Ç–∏
        if detections and self.tracked_objects:
            similarity_matrix = self._create_similarity_matrix(detections)
            matched_pairs = self._hungarian_matching(similarity_matrix)
        else:
            matched_pairs = []
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        matched_detections = set()
        matched_tracks = set()
        
        for det_idx, track_idx in matched_pairs:
            if similarity_matrix[det_idx][track_idx] > self.config.tracker_iou_threshold:
                track_id = list(self.tracked_objects.keys())[track_idx]
                detection = detections[det_idx]
                
                self.tracked_objects[track_id].update(detection)
                matched_detections.add(det_idx)
                matched_tracks.add(track_idx)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤
        for track_idx, track_id in enumerate(list(self.tracked_objects.keys())):
            if track_idx not in matched_tracks:
                obj = self.tracked_objects[track_id]
                obj.time_since_update += 1
                
                # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö —Ç—Ä–µ–∫–æ–≤
                if obj.time_since_update > self.config.tracker_max_age:
                    del self.tracked_objects[track_id]
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç—Ä–µ–∫–æ–≤ –¥–ª—è –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
        for det_idx, detection in enumerate(detections):
            if det_idx not in matched_detections:
                # –¢–æ–ª—å–∫–æ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–π —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ —Ç—Ä–µ–∫–∏
                if detection['confidence'] > 0.6:
                    self._create_new_track(detection)
        
        # –í–æ–∑–≤—Ä–∞—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤
        active_detections = []
        for obj in self.tracked_objects.values():
            if obj.time_since_update == 0 or obj.hit_streak >= self.config.tracker_min_hits:
                detection = obj.detection.copy()
                detection['object_id'] = obj.object_id
                detection['track_history'] = obj.track_history
                detection['age'] = obj.age
                detection['hit_streak'] = obj.hit_streak
                active_detections.append(detection)
        
        return active_detections
    
    def _create_similarity_matrix(self, detections):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –¥–µ—Ç–µ–∫—Ü–∏—è–º–∏ –∏ —Ç—Ä–µ–∫–∞–º–∏"""
        track_ids = list(self.tracked_objects.keys())
        similarity_matrix = np.zeros((len(detections), len(track_ids)))
        
        for det_idx, detection in enumerate(detections):
            for track_idx, track_id in enumerate(track_ids):
                obj = self.tracked_objects[track_id]
                similarity_matrix[det_idx][track_idx] = obj.similarity_score(detection)
        
        return similarity_matrix
    
    def _hungarian_matching(self, cost_matrix):
        """–í–µ–Ω–≥–µ—Ä—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è"""
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –º–∞—Ç—Ä–∏—Ü—É —Å—Ç–æ–∏–º–æ—Å—Ç–∏ (1 - —Å—Ö–æ–∂–µ—Å—Ç—å)
        cost_matrix = 1 - cost_matrix
        row_ind, col_ind = linear_sum_assignment(cost_matrix)
        return list(zip(row_ind, col_ind))
    
    def _create_new_track(self, detection):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ç—Ä–µ–∫–∞"""
        object_id = self.next_object_id
        self.tracked_objects[object_id] = TrackedObject(object_id, detection, self.config)
        self.next_object_id += 1

class RTSPYOLOProcessor:
    def __init__(self, config):
        self.config = config
        self.frame_size = config.capture_width * config.capture_height * 3
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —Ç—Ä–µ–∫–µ—Ä–∞
        self.object_tracker = AdvancedObjectTracker(config)
        
        # –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô –±—É—Ñ–µ—Ä –¥–ª—è –≤–µ–±-–≤—ã–≤–æ–¥–∞
        self.output_buffer = queue.Queue(maxsize=1)
        
        # –û—Ç–¥–µ–ª—å–Ω—ã–π –±—É—Ñ–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processing_buffer = queue.Queue(maxsize=5)
        
        self.running = False
        self.capture_frame_count = 0
        self.processed_frame_count = 0
        self.detection_count = 0
        self.start_time = time.time()
        
        # –ï–î–ò–ù–°–¢–í–ï–ù–ù–û–ï –º–µ—Å—Ç–æ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞
        self._current_output_frame = self._create_info_frame("Starting...")
        self._current_detections = []
        self._frame_lock = threading.Lock()

    def _create_info_frame(self, message):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –∫–∞–¥—Ä–∞"""
        frame = np.zeros((self.config.web_height, self.config.web_width, 3), dtype=np.uint8)
        
        # –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Ñ–æ–Ω
        for i in range(self.config.web_height):
            color = int(50 + (i / self.config.web_height) * 50)
            frame[i, :] = [color, color, color]
        
        text_y = self.config.web_height // 2
        cv2.putText(frame, message, (50, text_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
        
        return frame

    def start_ffmpeg(self):
        """–ó–∞–ø—É—Å–∫ FFmpeg —Å –§–ò–ö–°–ò–†–û–í–ê–ù–ù–´–ú —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ–º"""
        try:
            command = [
                'ffmpeg',
                '-i', self.config.rtsp_url,
                '-loglevel', 'quiet',
                '-an',
                '-fflags', 'nobuffer',
                '-flags', 'low_delay',
                '-f', 'image2pipe',
                '-pix_fmt', 'bgr24',
                '-vcodec', 'rawvideo',
                '-r', str(self.config.target_fps),
                '-s', f"{self.config.capture_width}x{self.config.capture_height}",
                '-'
            ]
            
            logger.info(f"üé• –ó–∞–ø—É—Å–∫ FFmpeg —Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ–º {self.config.capture_width}x{self.config.capture_height}")
            self.pipe = subprocess.Popen(command, 
                                       stdout=subprocess.PIPE,
                                       stderr=subprocess.PIPE,
                                       bufsize=10**8)
            logger.info("‚úÖ FFmpeg –∑–∞–ø—É—â–µ–Ω")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ FFmpeg: {e}")
            return False

    def load_yolo_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLO"""
        try:
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLO: {self.config.model_path}")
            self.model = YOLO(self.config.model_path)
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å YOLO –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ YOLO: {e}")
            return False

    def resize_frame_proportional(self, frame, target_width, target_height):
        """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∫–∞–¥—Ä–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π"""
        h, w = frame.shape[:2]
        
        aspect_ratio = w / h
        target_ratio = target_width / target_height
        
        if aspect_ratio > target_ratio:
            new_width = target_width
            new_height = int(target_width / aspect_ratio)
        else:
            new_height = target_height
            new_width = int(target_height * aspect_ratio)
        
        resized = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
        
        canvas = np.zeros((target_height, target_width, 3), dtype=np.uint8)
        
        y_offset = (target_height - new_height) // 2
        x_offset = (target_width - new_width) // 2
        
        canvas[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = resized
        
        return canvas

    def capture_frames(self):
        """–ó–∞—Ö–≤–∞—Ç –∫–∞–¥—Ä–æ–≤ –∏–∑ RTSP - –¢–û–õ–¨–ö–û –ó–ê–•–í–ê–¢"""
        logger.info("üé• –ó–∞–ø—É—Å–∫ –∑–∞—Ö–≤–∞—Ç–∞ –∫–∞–¥—Ä–æ–≤")
        
        consecutive_errors = 0
        max_errors = 5
        
        while self.running:
            try:
                ready, _, _ = select.select([self.pipe.stdout], [], [], 1.0)
                
                if ready:
                    raw_frame = self.pipe.stdout.read(self.frame_size)
                    
                    if len(raw_frame) == self.frame_size:
                        frame = np.frombuffer(raw_frame, dtype=np.uint8)
                        frame = frame.reshape((self.config.capture_height, self.config.capture_width, 3))
                        
                        # –ö–ª–∞–¥–µ–º –≤ –±—É—Ñ–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º –µ—Å–ª–∏ –ø–æ–ª–æ–Ω)
                        if not self.processing_buffer.full():
                            self.processing_buffer.put(frame)
                        
                        self.capture_frame_count += 1
                        consecutive_errors = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
                        
                    else:
                        logger.warning(f"–ù–µ–ø–æ–ª–Ω—ã–π –∫–∞–¥—Ä: {len(raw_frame)}/{self.frame_size}")
                        consecutive_errors += 1
                else:
                    logger.warning("–¢–∞–π–º–∞—É—Ç —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞")
                    consecutive_errors += 1
                
                # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø—Ä–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—à–∏–±–∫–∞—Ö
                if consecutive_errors >= max_errors:
                    logger.error("–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫, –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –∑–∞—Ö–≤–∞—Ç–∞...")
                    self.restart_ffmpeg()
                    consecutive_errors = 0
                    time.sleep(2)
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞: {e}")
                consecutive_errors += 1
                time.sleep(1)

    def restart_ffmpeg(self):
        """–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ FFmpeg –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö"""
        logger.info("–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ FFmpeg...")
        if hasattr(self, 'pipe'):
            try:
                self.pipe.terminate()
                self.pipe.wait(timeout=5)
            except:
                self.pipe.kill()
        time.sleep(1)
        return self.start_ffmpeg()

    def get_latest_frame(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞ - –ë–ï–ó –û–ß–ò–°–¢–ö–ò –ë–£–§–ï–†–û–í"""
        with self._frame_lock:
            return self._current_output_frame.copy(), self._current_detections.copy()

    def _get_color_by_id(self, object_id):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Ü–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ ID"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ö—ç—à –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤
        hue = (object_id * 50) % 180  # HSV hue –æ—Ç 0 –¥–æ 180
        hsv_color = np.uint8([[[hue, 255, 255]]])
        bgr_color = cv2.cvtColor(hsv_color, cv2.COLOR_HSV2BGR)
        return [int(c) for c in bgr_color[0][0]]

    def process_frames(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤ —Å YOLO - —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ç—Ä–µ–∫–∏–Ω–≥–æ–º"""
        logger.info("üîç –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ YOLO —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ç—Ä–µ–∫–∏–Ω–≥–æ–º")
        frame_counter = 0
        
        while self.running:
            try:
                # –ë–µ—Ä–µ–º –∫–∞–¥—Ä –∏–∑ –±—É—Ñ–µ—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                frame = self.processing_buffer.get(timeout=1.0)
                frame_counter += 1
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä
                if frame_counter % self.config.process_every_n == 0:
                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–∞–¥—Ä–∞ –¥–ª—è YOLO
                    processing_frame = self.resize_frame_proportional(
                        frame, 
                        self.config.processing_width, 
                        self.config.processing_height
                    )
                    
                    # YOLO –æ–±—Ä–∞–±–æ—Ç–∫–∞
                    results = self.model(processing_frame, 
                                       conf=self.config.confidence_threshold,
                                       verbose=False)
                    
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–π
                    detections = []
                    for result in results:
                        boxes = result.boxes
                        if boxes is not None:
                            for box in boxes:
                                cls = int(box.cls[0])
                                conf = float(box.conf[0])
                                xyxy = box.xyxy[0].tolist()
                                
                                detection = {
                                    'class': cls,
                                    'confidence': conf,
                                    'bbox': xyxy,
                                    'class_name': self.model.names[cls]
                                }
                                detections.append(detection)
                                self.detection_count += 1
                    
                    # –û–ë–ù–û–í–õ–ï–ù–ò–ï –£–õ–£–ß–®–ï–ù–ù–û–ì–û –¢–†–ï–ö–ï–†–ê
                    tracked_detections = self.object_tracker.update(detections)
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–¥—Ä–∞ –¥–ª—è –≤–µ–±-–≤—ã–≤–æ–¥–∞
                    web_frame = self.resize_frame_proportional(
                        frame,
                        self.config.web_width,
                        self.config.web_height
                    )
                    
                    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ bounding boxes
                    scale_x = self.config.web_width / self.config.processing_width
                    scale_y = self.config.web_height / self.config.processing_height
                    
                    # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–π —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
                    for det in tracked_detections:
                        x1, y1, x2, y2 = det['bbox']
                        x1 = int(x1 * scale_x)
                        y1 = int(y1 * scale_y) 
                        x2 = int(x2 * scale_x)
                        y2 = int(y2 * scale_y)
                        
                        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ü–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ ID
                        object_id = det.get('object_id', 0)
                        color = self._get_color_by_id(object_id)
                        
                        # –†–∏—Å—É–µ–º bounding box
                        cv2.rectangle(web_frame, (x1, y1), (x2, y2), color, 2)
                        
                        # –ü–æ–¥–ø–∏—Å—å —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                        age = det.get('age', 1)
                        hit_streak = det.get('hit_streak', 1)
                        label = f"ID:{object_id} {det['class_name']} {det['confidence']:.2f}"
                        sub_label = f"Age:{age} Hits:{hit_streak}"
                        
                        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
                        
                        # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                        cv2.rectangle(web_frame, (x1, y1-text_height-25), 
                                    (x1+text_width, y1), color, -1)
                        cv2.putText(web_frame, label, (x1, y1-15), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                        cv2.putText(web_frame, sub_label, (x1, y1-5), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
                        
                        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ç—Ä–µ–∫–∏–Ω–≥–∞
                        if 'track_history' in det and len(det['track_history']) > 1:
                            points = []
                            for point in det['track_history']:
                                px, py = point
                                px = int(px * scale_x)
                                py = int(py * scale_y)
                                points.append((px, py))
                            
                            # –†–∏—Å—É–µ–º –ø–ª–∞–≤–Ω—É—é –ª–∏–Ω–∏—é —Ç—Ä–µ–∫–∏–Ω–≥–∞
                            for i in range(1, len(points)):
                                thickness = max(1, int(3 * (i / len(points))))
                                cv2.line(web_frame, points[i-1], points[i], color, thickness)
                    
                    # –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                    current_time = datetime.now().strftime("%H:%M:%S")
                    elapsed = time.time() - self.start_time
                    fps = self.processed_frame_count / elapsed if elapsed > 0 else 0
                    
                    text_x = self.config.web_width - 220
                    stats_bg = np.zeros((100, 230, 3), dtype=np.uint8)
                    stats_bg[:,:] = [0, 0, 0]
                    
                    # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    web_frame[10:110, text_x-10:text_x+220] = (
                        web_frame[10:110, text_x-10:text_x+220] * 0.3 + stats_bg * 0.7
                    ).astype(np.uint8)
                    
                    cv2.putText(web_frame, f"Time: {current_time}", (text_x, 30), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
                    cv2.putText(web_frame, f"FPS: {fps:.1f}", (text_x, 50), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
                    cv2.putText(web_frame, f"Objects: {len(tracked_detections)}", (text_x, 70), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
                    cv2.putText(web_frame, f"Tracks: {len(self.object_tracker.tracked_objects)}", (text_x, 90), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
                    
                    # –û–ë–ù–û–í–õ–ï–ù–ò–ï —Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π!
                    with self._frame_lock:
                        self._current_output_frame = web_frame.copy()
                        self._current_detections = tracked_detections.copy()
                    
                    self.processed_frame_count += 1
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                time.sleep(0.1)

    def start_processing(self):
        """–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if not self.start_ffmpeg():
            return False
        
        if not self.load_yolo_model():
            return False
        
        self.running = True
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –∫–∞–¥—Ä–∞
        with self._frame_lock:
            self._current_output_frame = self._create_info_frame("Initializing...")
        
        # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–æ–≤
        capture_thread = threading.Thread(target=self.capture_frames, daemon=True)
        process_thread = threading.Thread(target=self.process_frames, daemon=True)
        
        capture_thread.start()
        time.sleep(3)  # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –∑–∞–ø—É—Å–∫ –∑–∞—Ö–≤–∞—Ç–∞
        process_thread.start()
        
        logger.info("‚úÖ –í—Å–µ –ø–æ—Ç–æ–∫–∏ –∑–∞–ø—É—â–µ–Ω—ã")
        return True

    def start_web_server(self):
        """–ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º FPS"""
        app = Flask(__name__)
        
        @app.route('/')
        def index():
            return """
            <!DOCTYPE html>
            <html>
            <head>
                <title>VisionGuard RTSP - Advanced Object Tracking</title>
                <meta charset="utf-8">
                <meta name="viewport" content="width=device-width, initial-scale=1">
                <style>
                    body { 
                        margin: 0; 
                        padding: 0;
                        background: #000;
                        overflow: hidden;
                        font-family: Arial, sans-serif;
                    }
                    #video {
                        width: 100vw;
                        height: 100vh;
                        object-fit: contain;
                    }
                    .stats {
                        position: absolute;
                        top: 10px;
                        left: 10px;
                        color: white;
                        background: rgba(0,0,0,0.7);
                        padding: 10px;
                        border-radius: 5px;
                        font-size: 14px;
                    }
                </style>
            </head>
            <body>
                <img id="video" src="/video_feed">
                <div class="stats" id="stats">Loading...</div>

                <script>
                    function refreshVideo() {
                        const video = document.getElementById('video');
                        const newSrc = '/video_feed?t=' + new Date().getTime();
                        
                        if (video.src !== newSrc) {
                            video.src = newSrc;
                        }
                    }

                    // –û–±–Ω–æ–≤–ª—è–µ–º –≤–∏–¥–µ–æ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
                    setInterval(refreshVideo, 300000);

                    // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ—Ñ—Ä–µ—à –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
                    document.getElementById('video').onerror = function() {
                        setTimeout(refreshVideo, 1000);
                    };

                    // –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    function updateStats() {
                        fetch('/stats')
                            .then(response => response.json())
                            .then(data => {
                                document.getElementById('stats').innerHTML = 
                                    `Objects: ${data.objects_count}<br>
                                     FPS: ${data.fps.toFixed(1)}<br>
                                     Total Tracks: ${data.total_tracks}<br>
                                     Processed: ${data.processed_frames}`;
                            })
                            .catch(() => {
                                document.getElementById('stats').innerHTML = 'Stats unavailable';
                            });
                    }

                    setInterval(updateStats, 1000);
                    updateStats();
                </script>
            </body>
            </html>
            """
        
        @app.route('/video_feed')
        def video_feed():
            def generate():
                target_fps = 10  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π FPS –¥–ª—è –≤–µ–±-–ø–æ—Ç–æ–∫–∞
                frame_interval = 1.0 / target_fps
                last_frame_time = 0
                
                while True:
                    try:
                        current_time = time.time()
                        
                        # –°—Ç—Ä–æ–≥–æ–µ —Å–æ–±–ª—é–¥–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ FPS
                        if current_time - last_frame_time >= frame_interval:
                            frame, detections = self.get_latest_frame()
                            
                            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), self.config.web_quality]
                            success, encoded_image = cv2.imencode('.jpg', frame, encode_param)
                            
                            if success:
                                yield (b'--frame\r\n'
                                       b'Content-Type: image/jpeg\r\n\r\n' + 
                                       encoded_image.tobytes() + b'\r\n')
                                last_frame_time = current_time
                        
                        # –°—Ç–∞–±–∏–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                        time.sleep(0.001)
                        
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –≤ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–µ: {e}")
                        time.sleep(0.1)
            
            return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')
        
        @app.route('/stats')
        def stats():
            elapsed = time.time() - self.start_time
            fps = self.processed_frame_count / elapsed if elapsed > 0 else 0
            
            return {
                'objects_count': len(self._current_detections),
                'fps': fps,
                'total_tracks': len(self.object_tracker.tracked_objects),
                'processed_frames': self.processed_frame_count,
                'total_detections': self.detection_count
            }
        
        logger.info(f"üåê –ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ http://{self.config.web_host}:{self.config.web_port}")
        app.run(host=self.config.web_host, port=self.config.web_port, threaded=True, debug=False)

    def start(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã"""
        if not self.start_processing():
            return False
        
        self.start_web_server()
        return True

    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞"""
        self.running = False
        if hasattr(self, 'pipe'):
            self.pipe.terminate()

def main():
    config = Config()
    processor = RTSPYOLOProcessor(config)
    
    try:
        if processor.start():
            logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –∑–∞–ø—É—â–µ–Ω–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ç—Ä–µ–∫–∏–Ω–≥–æ–º")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏—Å—Ç–µ–º—É")
    except KeyboardInterrupt:
        logger.info("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞: {e}")
    finally:
        processor.stop()

if __name__ == "__main__":
    main()