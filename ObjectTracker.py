#!/usr/bin/env python3
"""
Parking Lot Car Counter - RTSP to YOLO with Slanted Line Crossing Detection
"""

import cv2
import time
import logging
import subprocess
import numpy as np
import select
import threading
from flask import Flask, Response
from ultralytics import YOLO
import queue
import json
from datetime import datetime
import sys
from collections import OrderedDict, deque
import scipy.spatial as sp
from scipy.optimize import linear_sum_assignment

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('parking_counter.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class ParkingConfig:
    def __init__(self):
        # RTSP –∏—Å—Ç–æ—á–Ω–∏–∫
        self.rtsp_url = "rtsp://admin:Jaquio@172.30.0.68:554/live/main"
        self.model_path = "yolov8n.pt"
        
        # –†–∞–∑–º–µ—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.capture_width = 1920
        self.capture_height = 1080
        self.processing_width = 640
        self.processing_height = 360
        self.web_width = 854
        self.web_height = 480
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.target_fps = 20
        self.process_every_n = 2
        self.confidence_threshold = 0.5
        
        # –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
        self.web_host = "0.0.0.0"
        self.web_port = 8001
        self.web_quality = 60
        
        # –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –ü–ê–†–ö–û–í–ö–ò
        self.car_classes = [2, 5, 7]  # car, bus, truck –≤ COCO
        self.tracker_max_age = 45
        self.tracker_min_hits = 3
        self.tracker_iou_threshold = 0.3
        
        # –ù–ê–ö–õ–û–ù–ù–ê–Ø –õ–ò–ù–ò–Ø –ü–û–î–°–ß–ï–¢–ê (–Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ–¥ –≤–∞—à—É –∫–∞–º–µ—Ä—É)
        # –§–æ—Ä–º–∞—Ç: [(x1, y1), (x2, y2)] –≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö (0-1)
        # –õ–µ–≤—ã–π –∫—Ä–∞–π –Ω–∏–∂–µ —Ü–µ–Ω—Ç—Ä–∞, –ø—Ä–∞–≤—ã–π –≤—ã—à–µ —Ü–µ–Ω—Ç—Ä–∞
        self.counting_line = [(0.0, 0.8), (0.7, 0.4)]  # –ü—Ä–∏–º–µ—Ä –Ω–∞–∫–ª–æ–Ω–Ω–æ–π –ª–∏–Ω–∏–∏
        self.counting_direction = "up"  # "up" –∏–ª–∏ "down"

class KalmanFilter:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π Kalman —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —Ç—Ä–µ–∫–∏–Ω–≥–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π"""
    
    def __init__(self):
        self.state = np.zeros(6)
        self.covariance = np.eye(6) * 10
        
        self.transition_matrix = np.array([
            [1, 0, 0, 0, 1, 0],
            [0, 1, 0, 0, 0, 1],
            [0, 0, 1, 0, 0, 0],
            [0, 0, 0, 1, 0, 0],
            [0, 0, 0, 0, 1, 0],
            [0, 0, 0, 0, 0, 1]
        ])
        
        self.observation_matrix = np.array([
            [1, 0, 0, 0, 0, 0],
            [0, 1, 0, 0, 0, 0],
            [0, 0, 1, 0, 0, 0],
            [0, 0, 0, 1, 0, 0]
        ])
        
        self.process_noise = np.eye(6) * 0.03
        self.measurement_noise = np.eye(4) * 0.1
    
    def init(self, bbox):
        x1, y1, x2, y2 = bbox
        w, h = x2 - x1, y2 - y1
        cx, cy = x1 + w/2, y1 + h/2
        self.state = np.array([cx, cy, w, h, 0, 0])
        self.covariance = np.eye(6) * 10
    
    def predict(self):
        self.state = self.transition_matrix @ self.state
        self.covariance = (self.transition_matrix @ self.covariance @ 
                          self.transition_matrix.T) + self.process_noise
        return self.get_bbox()
    
    def update(self, bbox):
        if bbox is None:
            return
        
        x1, y1, x2, y2 = bbox
        w, h = x2 - x1, y2 - y1
        cx, cy = x1 + w/2, y1 + h/2
        measurement = np.array([cx, cy, w, h])
        
        y = measurement - self.observation_matrix @ self.state
        S = self.observation_matrix @ self.covariance @ self.observation_matrix.T + self.measurement_noise
        K = self.covariance @ self.observation_matrix.T @ np.linalg.inv(S)
        
        self.state = self.state + K @ y
        self.covariance = (np.eye(6) - K @ self.observation_matrix) @ self.covariance
    
    def get_bbox(self):
        cx, cy, w, h, _, _ = self.state
        x1 = cx - w/2
        y1 = cy - h/2
        x2 = cx + w/2
        y2 = cy + h/2
        return [x1, y1, x2, y2]

class TrackedVehicle:
    """–¢—Ä–µ–∫–∞–µ–º—ã–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å —Å –ø–æ–¥—Å—á–µ—Ç–æ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –Ω–∞–∫–ª–æ–Ω–Ω–æ–π –ª–∏–Ω–∏–∏"""
    
    def __init__(self, object_id, detection, config):
        self.object_id = object_id
        self.detection = detection
        self.class_name = detection['class_name']
        self.confidence = detection['confidence']
        
        # Kalman —Ñ–∏–ª—å—Ç—Ä
        self.kalman = KalmanFilter()
        self.kalman.init(detection['bbox'])
        
        # –ò—Å—Ç–æ—Ä–∏—è –ø–æ–∑–∏—Ü–∏–π
        self.track_history = deque(maxlen=30)
        
        # –°—Ç–∞—Ç—É—Å —Ç—Ä–µ–∫–∏–Ω–≥–∞
        self.hit_streak = 1
        self.age = 1
        self.time_since_update = 0
        
        # –î–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –ª–∏–Ω–∏–∏
        self.last_position = None
        self.has_crossed_line = False
        self.crossing_direction = None
        
        self.config = config
        self.update_track_history()
    
    def update_track_history(self):
        bbox = self.kalman.get_bbox()
        cx = (bbox[0] + bbox[2]) / 2
        cy = (bbox[1] + bbox[3]) / 2
        self.track_history.append((cx, cy))
        
        current_pos = cy
        if self.last_position is not None:
            if current_pos < self.last_position:
                self.crossing_direction = "up"
            else:
                self.crossing_direction = "down"
        self.last_position = current_pos
    
    def predict(self):
        predicted_bbox = self.kalman.predict()
        self.age += 1
        self.time_since_update += 1
        self.update_track_history()
        return predicted_bbox
    
    def update(self, detection):
        self.detection = detection
        self.confidence = detection['confidence']
        self.kalman.update(detection['bbox'])
        self.hit_streak += 1
        self.time_since_update = 0
        self.update_track_history()
    
    def check_line_crossing(self, line_start, line_end):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –Ω–∞–∫–ª–æ–Ω–Ω–æ–π –ª–∏–Ω–∏–∏ –ø–æ–¥—Å—á–µ—Ç–∞"""
        if len(self.track_history) < 2:
            return False, None
        
        current_point = self.track_history[-1]
        previous_point = self.track_history[-2]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –ª–∏–Ω–∏–∏
        if self._line_intersection(previous_point, current_point, line_start, line_end):
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ª–∏–Ω–∏–∏
            direction = self._get_crossing_direction(previous_point, current_point, line_start, line_end)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±—É–µ–º–æ–º—É –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é
            if direction == self.config.counting_direction and not self.has_crossed_line:
                self.has_crossed_line = True
                return True, direction
        
        return False, None
    
    def _line_intersection(self, p1, p2, p3, p4):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –¥–≤—É—Ö –æ—Ç—Ä–µ–∑–∫–æ–≤"""
        def ccw(A, B, C):
            return (C[1]-A[1]) * (B[0]-A[0]) > (B[1]-A[1]) * (C[0]-A[0])
        
        A, B, C, D = p1, p2, p3, p4
        return ccw(A, C, D) != ccw(B, C, D) and ccw(A, B, C) != ccw(A, B, D)
    
    def _get_crossing_direction(self, prev_point, curr_point, line_start, line_end):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–∞–∫–ª–æ–Ω–Ω–æ–π –ª–∏–Ω–∏–∏"""
        # –í–µ–∫—Ç–æ—Ä –ª–∏–Ω–∏–∏
        line_vector = (line_end[0] - line_start[0], line_end[1] - line_start[1])
        
        # –í–µ–∫—Ç–æ—Ä –¥–≤–∏–∂–µ–Ω–∏—è
        move_vector = (curr_point[0] - prev_point[0], curr_point[1] - prev_point[1])
        
        # –í–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω—ã
        cross_product = line_vector[0] * move_vector[1] - line_vector[1] * move_vector[0]
        
        # –î–ª—è –Ω–∞–∫–ª–æ–Ω–Ω–æ–π –ª–∏–Ω–∏–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–µ
        if cross_product > 0:
            return "up" if line_vector[0] > 0 else "down"
        else:
            return "down" if line_vector[0] > 0 else "up"
    
    def similarity_score(self, detection):
        """–û—Ü–µ–Ω–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –Ω–æ–≤–æ–π –¥–µ—Ç–µ–∫—Ü–∏–µ–π"""
        bbox1 = self.kalman.get_bbox()
        bbox2 = detection['bbox']
        
        iou = self._calculate_iou(bbox1, bbox2)
        class_similarity = 1.0 if self.class_name == detection['class_name'] else 0.0
        
        return iou * 0.7 + class_similarity * 0.3
    
    def _calculate_iou(self, box1, box2):
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        
        xi1 = max(x1_1, x1_2)
        yi1 = max(y1_1, y1_2)
        xi2 = min(x2_1, x2_2)
        yi2 = min(y2_1, y2_2)
        
        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
        box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)
        box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)
        union_area = box1_area + box2_area - inter_area
        
        return inter_area / union_area if union_area > 0 else 0

class ParkingLotTracker:
    """–¢—Ä–µ–∫–µ—Ä –¥–ª—è –ø–∞—Ä–∫–æ–≤–∫–∏ —Å –ø–æ–¥—Å—á–µ—Ç–æ–º –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π —á–µ—Ä–µ–∑ –Ω–∞–∫–ª–æ–Ω–Ω—É—é –ª–∏–Ω–∏—é"""
    
    def __init__(self, config):
        self.config = config
        self.next_object_id = 1
        self.tracked_vehicles = OrderedDict()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∫–æ–≤–∫–∏
        self.vehicles_in = 0
        self.vehicles_out = 0
        self.current_vehicles = 0
        
    def update(self, detections):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–µ—Ä–∞ —Å –ø–æ–¥—Å—á–µ—Ç–æ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π"""
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π
        for vehicle in self.tracked_vehicles.values():
            vehicle.predict()
        
        # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–π —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Ç—Ä–µ–∫–∞–º–∏
        if detections and self.tracked_vehicles:
            similarity_matrix = self._create_similarity_matrix(detections)
            matched_pairs = self._hungarian_matching(similarity_matrix)
        else:
            matched_pairs = []
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        matched_detections = set()
        matched_tracks = set()
        
        for det_idx, track_idx in matched_pairs:
            if similarity_matrix[det_idx][track_idx] > self.config.tracker_iou_threshold:
                track_id = list(self.tracked_vehicles.keys())[track_idx]
                detection = detections[det_idx]
                
                self.tracked_vehicles[track_id].update(detection)
                matched_detections.add(det_idx)
                matched_tracks.add(track_idx)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö —Ç—Ä–µ–∫–æ–≤
        for track_idx, track_id in enumerate(list(self.tracked_vehicles.keys())):
            if track_idx not in matched_tracks:
                vehicle = self.tracked_vehicles[track_id]
                vehicle.time_since_update += 1
                
                if vehicle.time_since_update > self.config.tracker_max_age:
                    del self.tracked_vehicles[track_id]
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç—Ä–µ–∫–æ–≤
        for det_idx, detection in enumerate(detections):
            if det_idx not in matched_detections:
                if detection['confidence'] > 0.6:
                    self._create_new_track(detection)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –ª–∏–Ω–∏–∏ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self._check_line_crossings()
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
        self.current_vehicles = len(self.tracked_vehicles)
        
        # –í–æ–∑–≤—Ä–∞—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤
        active_detections = []
        for vehicle in self.tracked_vehicles.values():
            if vehicle.time_since_update == 0 or vehicle.hit_streak >= self.config.tracker_min_hits:
                detection = vehicle.detection.copy()
                detection['object_id'] = vehicle.object_id
                detection['track_history'] = vehicle.track_history
                detection['has_crossed_line'] = vehicle.has_crossed_line
                active_detections.append(detection)
        
        return active_detections
    
    def _check_line_crossings(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –Ω–∞–∫–ª–æ–Ω–Ω–æ–π –ª–∏–Ω–∏–∏ –ø–æ–¥—Å—á–µ—Ç–∞ –¥–ª—è –≤—Å–µ—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ª–∏–Ω–∏–∏ –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –¥–ª—è processing –∫–∞–¥—Ä–∞
        line_start = (
            self.config.counting_line[0][0] * self.config.processing_width,
            self.config.counting_line[0][1] * self.config.processing_height
        )
        line_end = (
            self.config.counting_line[1][0] * self.config.processing_width,
            self.config.counting_line[1][1] * self.config.processing_height
        )
        
        for vehicle in self.tracked_vehicles.values():
            crossed, direction = vehicle.check_line_crossing(line_start, line_end)
            
            if crossed:
                if direction == "up":
                    self.vehicles_in += 1
                    logger.info(f"üöó –í–™–ï–•–ê–õ–ê –º–∞—à–∏–Ω–∞! –í—Å–µ–≥–æ –≤—ä–µ—Ö–∞–ª–æ: {self.vehicles_in}")
                else:
                    self.vehicles_out += 1
                    logger.info(f"üöó –í–´–ï–•–ê–õ–ê –º–∞—à–∏–Ω–∞! –í—Å–µ–≥–æ –≤—ã–µ—Ö–∞–ª–æ: {self.vehicles_out}")
    
    def _create_similarity_matrix(self, detections):
        track_ids = list(self.tracked_vehicles.keys())
        similarity_matrix = np.zeros((len(detections), len(track_ids)))
        
        for det_idx, detection in enumerate(detections):
            for track_idx, track_id in enumerate(track_ids):
                vehicle = self.tracked_vehicles[track_id]
                similarity_matrix[det_idx][track_idx] = vehicle.similarity_score(detection)
        
        return similarity_matrix
    
    def _hungarian_matching(self, cost_matrix):
        cost_matrix = 1 - cost_matrix
        row_ind, col_ind = linear_sum_assignment(cost_matrix)
        return list(zip(row_ind, col_ind))
    
    def _create_new_track(self, detection):
        object_id = self.next_object_id
        self.tracked_vehicles[object_id] = TrackedVehicle(object_id, detection, self.config)
        self.next_object_id += 1
        logger.info(f"üÜï –ù–æ–≤—ã–π —Ç—Ä–µ–∫: ID:{object_id} {detection['class_name']}")

class ParkingLotProcessor:
    def __init__(self, config):
        self.config = config
        self.frame_size = config.capture_width * config.capture_height * 3
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞ –ø–∞—Ä–∫–æ–≤–∫–∏
        self.parking_tracker = ParkingLotTracker(config)
        
        # –ë—É—Ñ–µ—Ä—ã
        self.processing_buffer = queue.Queue(maxsize=5)
        
        self.running = False
        self.capture_frame_count = 0
        self.processed_frame_count = 0
        self.start_time = time.time()
        
        # –¢–µ–∫—É—â–∏–π –∫–∞–¥—Ä –¥–ª—è –≤—ã–≤–æ–¥–∞
        self._current_output_frame = self._create_info_frame("Starting Parking Lot Monitor...")
        self._current_detections = []
        self._frame_lock = threading.Lock()

    def _create_info_frame(self, message):
        frame = np.zeros((self.config.web_height, self.config.web_width, 3), dtype=np.uint8)
        
        for i in range(self.config.web_height):
            color = int(50 + (i / self.config.web_height) * 50)
            frame[i, :] = [color, color, color]
        
        text_y = self.config.web_height // 2
        cv2.putText(frame, message, (50, text_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
        
        return frame

    def start_ffmpeg(self):
        try:
            command = [
                'ffmpeg',
                '-i', self.config.rtsp_url,
                '-loglevel', 'quiet',
                '-an',
                '-fflags', 'nobuffer',
                '-flags', 'low_delay',
                '-f', 'image2pipe',
                '-pix_fmt', 'bgr24',
                '-vcodec', 'rawvideo',
                '-r', str(self.config.target_fps),
                '-s', f"{self.config.capture_width}x{self.config.capture_height}",
                '-'
            ]
            
            logger.info(f"üé• –ó–∞–ø—É—Å–∫ FFmpeg –¥–ª—è –ø–∞—Ä–∫–æ–≤–∫–∏")
            self.pipe = subprocess.Popen(command, 
                                       stdout=subprocess.PIPE,
                                       stderr=subprocess.PIPE,
                                       bufsize=10**8)
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ FFmpeg: {e}")
            return False

    def load_yolo_model(self):
        try:
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLO: {self.config.model_path}")
            self.model = YOLO(self.config.model_path)
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å YOLO –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ YOLO: {e}")
            return False

    def resize_frame_proportional(self, frame, target_width, target_height):
        h, w = frame.shape[:2]
        
        aspect_ratio = w / h
        target_ratio = target_width / target_height
        
        if aspect_ratio > target_ratio:
            new_width = target_width
            new_height = int(target_width / aspect_ratio)
        else:
            new_height = target_height
            new_width = int(target_height * aspect_ratio)
        
        resized = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
        
        canvas = np.zeros((target_height, target_width, 3), dtype=np.uint8)
        y_offset = (target_height - new_height) // 2
        x_offset = (target_width - new_width) // 2
        
        canvas[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = resized
        
        return canvas

    def capture_frames(self):
        logger.info("üé• –ó–∞–ø—É—Å–∫ –∑–∞—Ö–≤–∞—Ç–∞ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –ø–∞—Ä–∫–æ–≤–∫–∏")
        
        consecutive_errors = 0
        max_errors = 5
        
        while self.running:
            try:
                ready, _, _ = select.select([self.pipe.stdout], [], [], 1.0)
                
                if ready:
                    raw_frame = self.pipe.stdout.read(self.frame_size)
                    
                    if len(raw_frame) == self.frame_size:
                        frame = np.frombuffer(raw_frame, dtype=np.uint8)
                        frame = frame.reshape((self.config.capture_height, self.config.capture_width, 3))
                        
                        if not self.processing_buffer.full():
                            self.processing_buffer.put(frame)
                        
                        self.capture_frame_count += 1
                        consecutive_errors = 0
                    else:
                        logger.warning(f"–ù–µ–ø–æ–ª–Ω—ã–π –∫–∞–¥—Ä: {len(raw_frame)}/{self.frame_size}")
                        consecutive_errors += 1
                else:
                    consecutive_errors += 1
                
                if consecutive_errors >= max_errors:
                    logger.error("–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –∑–∞—Ö–≤–∞—Ç–∞...")
                    self.restart_ffmpeg()
                    consecutive_errors = 0
                    time.sleep(2)
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞: {e}")
                consecutive_errors += 1
                time.sleep(1)

    def restart_ffmpeg(self):
        logger.info("–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ FFmpeg...")
        if hasattr(self, 'pipe'):
            try:
                self.pipe.terminate()
                self.pipe.wait(timeout=5)
            except:
                self.pipe.kill()
        time.sleep(1)
        return self.start_ffmpeg()

    def get_latest_frame(self):
        with self._frame_lock:
            return self._current_output_frame.copy(), self._current_detections.copy()

    def _get_color_by_id(self, object_id):
        hue = (object_id * 50) % 180
        hsv_color = np.uint8([[[hue, 255, 255]]])
        bgr_color = cv2.cvtColor(hsv_color, cv2.COLOR_HSV2BGR)
        return [int(c) for c in bgr_color[0][0]]

    def _draw_parking_info(self, frame):
        """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∞—Ä–∫–æ–≤–∫–µ –Ω–∞ –∫–∞–¥—Ä–µ"""
        h, w = frame.shape[:2]
        
        # –ù–∞–∫–ª–æ–Ω–Ω–∞—è –ª–∏–Ω–∏—è –ø–æ–¥—Å—á–µ—Ç–∞
        line_start = (
            int(self.config.counting_line[0][0] * w),
            int(self.config.counting_line[0][1] * h)
        )
        line_end = (
            int(self.config.counting_line[1][0] * w),
            int(self.config.counting_line[1][1] * h)
        )
        
        cv2.line(frame, line_start, line_end, (0, 255, 255), 2)
        cv2.putText(frame, "COUNTING LINE", (line_start[0], line_start[1] - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∫–æ–≤–∫–∏
        stats_text = f"IN: {self.parking_tracker.vehicles_in} OUT: {self.parking_tracker.vehicles_out}"
        cv2.putText(frame, stats_text, (w - 200, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return frame

    def process_frames(self):
        logger.info("üîç –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –ø–∞—Ä–∫–æ–≤–∫–∏")
        frame_counter = 0
        
        while self.running:
            try:
                frame = self.processing_buffer.get(timeout=1.0)
                frame_counter += 1
                
                if frame_counter % self.config.process_every_n == 0:
                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–∞–¥—Ä–∞ –¥–ª—è YOLO
                    processing_frame = self.resize_frame_proportional(
                        frame, 
                        self.config.processing_width, 
                        self.config.processing_height
                    )
                    
                    # YOLO –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¢–û–õ–¨–ö–û –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
                    results = self.model(processing_frame, 
                                       conf=self.config.confidence_threshold,
                                       classes=self.config.car_classes,
                                       verbose=False)
                    
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–π –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
                    detections = []
                    for result in results:
                        boxes = result.boxes
                        if boxes is not None:
                            for box in boxes:
                                cls = int(box.cls[0])
                                conf = float(box.conf[0])
                                xyxy = box.xyxy[0].tolist()
                                
                                detection = {
                                    'class': cls,
                                    'confidence': conf,
                                    'bbox': xyxy,
                                    'class_name': self.model.names[cls]
                                }
                                detections.append(detection)
                    
                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–µ—Ä–∞ –ø–∞—Ä–∫–æ–≤–∫–∏
                    try:
                        tracked_detections = self.parking_tracker.update(detections)
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞: {e}")
                        tracked_detections = []
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–¥—Ä–∞ –¥–ª—è –≤–µ–±-–≤—ã–≤–æ–¥–∞
                    web_frame = self.resize_frame_proportional(
                        frame,
                        self.config.web_width,
                        self.config.web_height
                    )
                    
                    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ bounding boxes
                    scale_x = self.config.web_width / self.config.processing_width
                    scale_y = self.config.web_height / self.config.processing_height
                    
                    # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–π
                    for det in tracked_detections:
                        try:
                            x1, y1, x2, y2 = det['bbox']
                            x1 = int(x1 * scale_x)
                            y1 = int(y1 * scale_y) 
                            x2 = int(x2 * scale_x)
                            y2 = int(y2 * scale_y)
                            
                            object_id = det.get('object_id', 0)
                            color = self._get_color_by_id(object_id)
                            
                            # –†–∏—Å—É–µ–º bounding box
                            cv2.rectangle(web_frame, (x1, y1), (x2, y2), color, 2)
                            
                            # –ü–æ–¥–ø–∏—Å—å
                            label = f"ID:{object_id} {det['class_name']} {det['confidence']:.2f}"
                            if det.get('has_crossed_line', False):
                                label += " COUNTED"
                            
                            (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
                            cv2.rectangle(web_frame, (x1, y1-text_height-10), 
                                        (x1+text_width, y1), color, -1)
                            cv2.putText(web_frame, label, (x1, y1-5), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                            
                            # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ç—Ä–µ–∫–∏–Ω–≥–∞
                            if 'track_history' in det and len(det['track_history']) > 1:
                                points = []
                                for point in det['track_history']:
                                    px, py = point
                                    px = int(px * scale_x)
                                    py = int(py * scale_y)
                                    points.append((px, py))
                                
                                for i in range(1, len(points)):
                                    thickness = max(1, int(3 * (i / len(points))))
                                    cv2.line(web_frame, points[i-1], points[i], color, thickness)
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}")
                            continue
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä–∫–æ–≤–∫–µ
                    web_frame = self._draw_parking_info(web_frame)
                    
                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–¥—Ä–∞
                    with self._frame_lock:
                        self._current_output_frame = web_frame.copy()
                        self._current_detections = tracked_detections.copy()
                    
                    self.processed_frame_count += 1
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                time.sleep(0.1)

    def start_web_server(self):
        app = Flask(__name__)
        
        @app.route('/')
        def index():
            return """
            <!DOCTYPE html>
            <html>
            <head>
                <title>Parking Lot Car Counter</title>
                <meta charset="utf-8">
                <style>
                    body { 
                        margin: 0; 
                        padding: 0;
                        background: #000;
                        overflow: hidden;
                        font-family: Arial, sans-serif;
                    }
                    #video {
                        width: 100vw;
                        height: 100vh;
                        object-fit: contain;
                    }
                </style>
            </head>
            <body>
                <img id="video" src="/video_feed">

                <script>
                    function refreshVideo() {
                        const video = document.getElementById('video');
                        video.src = '/video_feed?t=' + new Date().getTime();
                    }

                    // –û–±–Ω–æ–≤–ª—è–µ–º –≤–∏–¥–µ–æ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
                    setInterval(refreshVideo, 300000);

                    // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ—Ñ—Ä–µ—à –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
                    document.getElementById('video').onerror = function() {
                        setTimeout(refreshVideo, 1000);
                    };
                </script>
            </body>
            </html>
            """
        
        @app.route('/video_feed')
        def video_feed():
            def generate():
                target_fps = 10
                frame_interval = 1.0 / target_fps
                last_frame_time = 0
                
                while True:
                    try:
                        current_time = time.time()
                        if current_time - last_frame_time >= frame_interval:
                            frame, detections = self.get_latest_frame()
                            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), self.config.web_quality]
                            success, encoded_image = cv2.imencode('.jpg', frame, encode_param)
                            if success:
                                yield (b'--frame\r\n'
                                       b'Content-Type: image/jpeg\r\n\r\n' + 
                                       encoded_image.tobytes() + b'\r\n')
                                last_frame_time = current_time
                        time.sleep(0.001)
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –≤ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–µ: {e}")
                        time.sleep(0.1)
            return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')
        
        @app.route('/stats')
        def stats():
            elapsed = time.time() - self.start_time
            fps = self.processed_frame_count / elapsed if elapsed > 0 else 0
            
            return {
                'vehicles_in': self.parking_tracker.vehicles_in,
                'vehicles_out': self.parking_tracker.vehicles_out,
                'current_vehicles': self.parking_tracker.current_vehicles,
                'fps': round(fps, 1),
                'processed_frames': self.processed_frame_count,
                'uptime': round(elapsed, 1)
            }
        
        @app.route('/reset')
        def reset_counters():
            self.parking_tracker.vehicles_in = 0
            self.parking_tracker.vehicles_out = 0
            return {"status": "counters reset"}
        
        logger.info(f"üåê –ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞ –ø–∞—Ä–∫–æ–≤–∫–∏ –Ω–∞ http://{self.config.web_host}:{self.config.web_port}")
        app.run(host=self.config.web_host, port=self.config.web_port, threaded=True, debug=False)

    def start_processing(self):
        if not self.start_ffmpeg():
            return False
        
        if not self.load_yolo_model():
            return False
        
        self.running = True
        
        with self._frame_lock:
            self._current_output_frame = self._create_info_frame("Initializing Parking Lot Monitor...")
        
        capture_thread = threading.Thread(target=self.capture_frames, daemon=True)
        process_thread = threading.Thread(target=self.process_frames, daemon=True)
        
        capture_thread.start()
        time.sleep(3)
        process_thread.start()
        
        logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø–æ–¥—Å—á–µ—Ç–∞ –ø–∞—Ä–∫–æ–≤–∫–∏ –∑–∞–ø—É—â–µ–Ω–∞")
        return True

    def start(self):
        if not self.start_processing():
            return False
        
        self.start_web_server()
        return True

    def stop(self):
        self.running = False
        if hasattr(self, 'pipe'):
            self.pipe.terminate()

def main():
    config = ParkingConfig()
    processor = ParkingLotProcessor(config)
    
    try:
        if processor.start():
            logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø–æ–¥—Å—á–µ—Ç–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –Ω–∞ –ø–∞—Ä–∫–æ–≤–∫–µ –∑–∞–ø—É—â–µ–Ω–∞")
            logger.info("üöó –ù–∞—Å—Ç—Ä–æ–π—Ç–µ counting_line –≤ –∫–æ–Ω—Ñ–∏–≥–µ –ø–æ–¥ –≤–∞—à—É –∫–∞–º–µ—Ä—É")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏—Å—Ç–µ–º—É")
    except KeyboardInterrupt:
        logger.info("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞: {e}")
    finally:
        processor.stop()

if __name__ == "__main__":
    main()